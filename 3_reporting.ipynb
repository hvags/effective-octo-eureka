{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917b20b3",
   "metadata": {},
   "source": [
    "# Final Project - Evaluation Run and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735b15c",
   "metadata": {},
   "source": [
    "## Installing packages (if running on colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31fb7d4",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Uncomment and run the cell below and then restart the Runtime (Menu Runtime > Restart Runtime, or with Ctrl + M .), then run it again. If you do not do that, then you will get errors. You only need to run it again if your Google Colab / Kaggle instance is restarted or lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5851246",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "! pip install --upgrade scipy\n",
    "! pip install --upgrade pandas\n",
    "! pip install ipywidgets\n",
    "! pip uninstall -y pykeen\n",
    "! pip install git+https://github.com/pykeen/pykeen.git@v1.5.0\n",
    "! python -c \"import pykeen\" || pip install git+https://github.com/pykeen/pykeen.git@v1.5.0\n",
    "from pkg_resources import require\n",
    "require('pykeen')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79cad50",
   "metadata": {},
   "source": [
    "After you install the packages above, you can just run from this cell onwards (Ctrl + F10 when this is selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a779c",
   "metadata": {},
   "source": [
    "## Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28662abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.pipeline import pipeline_from_config\n",
    "from pykeen.triples import TriplesFactory\n",
    "import os.path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa89fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this value for BASE_DATA_URL if working with local data\n",
    "# BASE_DATA_URL = './data'\n",
    "\n",
    "# Use this value for HPO_URL_BASE if working with local data\n",
    "# HPO_URL_BASE = './hpo_results'\n",
    "\n",
    "# Use this value for BASE_DATA_URL if working with data from the github repo\n",
    "BASE_DATA_URL = 'https://raw.githubusercontent.com/hvags/effective-octo-eureka/main/data'\n",
    "\n",
    "# Use this value for HPO_URL_BASE if working with data from the github repo\n",
    "HPO_URL_BASE = 'https://raw.githubusercontent.com/hvags/effective-octo-eureka/main/hpo_results'\n",
    "\n",
    "HPO_URL_TAIL = 'best_pipeline/pipeline_config.json'\n",
    "\n",
    "# Run on GPU\n",
    "CPU_DEV = 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ed13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd10e7",
   "metadata": {},
   "source": [
    "## wn18rr datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['wn18rr-full'] = {\n",
    "    'train': '/wn18rr/train_wn18rr.txt',\n",
    "    'validate': '/wn18rr/valid_wn18rr.txt',\n",
    "    'test': '/wn18rr/test_wn18rr.txt'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443164bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['wn18rr-sym'] = {\n",
    "    'train': '/wn18rr/sym_train_wn18rr.txt',\n",
    "    'validate': '/wn18rr/sym_valid_wn18rr.txt',\n",
    "    'test': '/wn18rr/sym_test_wn18rr.txt'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c96dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['wn18rr-asym'] = {\n",
    "    'train': '/wn18rr/asym_train_wn18rr.txt',\n",
    "    'validate': '/wn18rr/asym_valid_wn18rr.txt',\n",
    "    'test': '/wn18rr/asym_test_wn18rr.txt'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9a09b",
   "metadata": {},
   "source": [
    "## fb15k-237 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66014b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['fb15k-237-full'] = {\n",
    "    'train':  '/fb15k-237/train_fb15k-237.txt',\n",
    "    'validate': '/fb15k-237/valid_fb15k-237.txt',\n",
    "    'test': '/fb15k-237/test_fb15k-237.txt'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['fb15k-237-sym'] = {\n",
    "    'train': '/fb15k-237/sym_train_fb15k-237.txt',\n",
    "    'validate': '/fb15k-237/sym_valid_fb15k-237.txt',\n",
    "    'test': '/fb15k-237/sym_test_fb15k-237.txt'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls['fb15k-237-asym'] = {\n",
    "    'train': '/fb15k-237/asym_train_fb15k-237.txt',\n",
    "    'validate': '/fb15k-237/asym_valid_fb15k-237.txt',\n",
    "    'test': '/fb15k-237/asym_test_fb15k-237.txt'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6bbee",
   "metadata": {},
   "source": [
    "## Read data from files and create TriplesFactories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "\n",
    "for key in dataset_urls.keys():\n",
    "    print(f'Processing: {key}')\n",
    "    \n",
    "    datasets[key] = dict()\n",
    "    \n",
    "    df_train = pd.read_csv(BASE_DATA_URL + dataset_urls[key]['train'], header=None, sep='\\t', names=['head', 'relation','tail'])\n",
    "    df_validate = pd.read_csv(BASE_DATA_URL + dataset_urls[key]['validate'], header=None, sep='\\t', names=['head', 'relation','tail'])\n",
    "    df_test = pd.read_csv(BASE_DATA_URL + dataset_urls[key]['test'], header=None, sep='\\t', names=['head', 'relation','tail'])\n",
    "    \n",
    "    datasets[key]['train'] = TriplesFactory.from_labeled_triples(df_train.astype('str').to_numpy())\n",
    "    entity_mapping = datasets[key]['train'].entity_to_id\n",
    "    relation_mapping = datasets[key]['train'].relation_to_id\n",
    "    \n",
    "    datasets[key]['validate'] = TriplesFactory.from_labeled_triples(df_validate.astype('str').to_numpy(),\n",
    "                                                                    entity_to_id=entity_mapping,\n",
    "                                                                    relation_to_id=relation_mapping\n",
    "                                                                    )\n",
    "    \n",
    "    datasets[key]['test'] = TriplesFactory.from_labeled_triples(df_test.astype('str').to_numpy(),\n",
    "                                                                    entity_to_id=entity_mapping,\n",
    "                                                                    relation_to_id=relation_mapping\n",
    "                                                                    )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b076a",
   "metadata": {},
   "source": [
    "## Models to include in the evaluation\n",
    "\n",
    "If doing a partial run, comment out models that should not be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c56107",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          'TransE',\n",
    "          'TransH',\n",
    "          'TransD',\n",
    "          'TransR',\n",
    "          'RESCAL',\n",
    "          'ComplEx',\n",
    "          'RotatE'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "for dataset_name, dataset_url in dataset_urls.items():    \n",
    "    for model in models:        \n",
    "        url = f'{HPO_URL_BASE}/{dataset_name}/{model}/{HPO_URL_TAIL}'        \n",
    "        \n",
    "        if not (url.startswith('http')):\n",
    "            if not (os.path.exists(url)):\n",
    "                print(url, ' - file not found')\n",
    "                continue\n",
    "            else:\n",
    "                with open(url) as file:\n",
    "                    config = json.load(file)\n",
    "        \n",
    "        else:\n",
    "            response = requests.get(url).text\n",
    "\n",
    "            if (response.startswith('404')):\n",
    "                print(url, response)\n",
    "                continue\n",
    "\n",
    "            config = json.loads(response)\n",
    "\n",
    "        config['pipeline'].pop('testing')\n",
    "        config['pipeline'].pop('training')\n",
    "        config['pipeline'].pop('validation')        \n",
    "        \n",
    "        if (config['pipeline']['loss'] == 'marginranking'):\n",
    "            if('margin_activation' in config['pipeline']['loss_kwargs']):\n",
    "                config['pipeline']['loss_kwargs'].pop('margin_activation')\n",
    "        \n",
    "        dataset = datasets[dataset_name]\n",
    "        print(dataset_name + ' loaded')\n",
    "        results[dataset_name, model] = pipeline_from_config(config,\n",
    "                              device=CPU_DEV,\n",
    "                              testing=dataset['test'],\n",
    "                              training=dataset['train'],\n",
    "                              validation=dataset['validate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28df386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_table(results):\n",
    "  \n",
    "    metrics = [('both.realistic.mean_reciprocal_rank', 'MRR'),                  \n",
    "                ('both.realistic.hits@1', 'Hits@1'),                \n",
    "                ('both.realistic.hits@10', 'Hits@10')]         \n",
    "   \n",
    "    \n",
    "    for dataset in dataset_urls.keys():\n",
    "        print(dataset)\n",
    "        table = pd.DataFrame()\n",
    "       \n",
    "        for model_label in models:                            \n",
    "            row = [model_label]\n",
    "            \n",
    "            for metric in metrics:      \n",
    "                if ((dataset, model_label) not in results):\n",
    "                    result = 'NaN'\n",
    "                    row += [result]\n",
    "                else:\n",
    "                    result = results[(dataset, model_label)].get_metric(metric[0])\n",
    "                    row += [round(result,5)]                \n",
    "            table = table.append(pd.DataFrame([row], columns =['model'] + [metric[1] for metric in metrics]))\n",
    "\n",
    "        print(table.to_string(index=False))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87befb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_table(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
